{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data\n",
    "Importing data from tweets.csv and splitting into training and test sets. Data fields used are \"airline_sentiment\" and \"text\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[\"text\"]\n",
    "y = data[\"airline_sentiment\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "Generating a vocabulary using functions for tokenizing, stemming, and lemmatizing tweets using nltk stopwords, SnowBallStemmer, WordnetLemmatizer, and a tokenization function inspired by freeCodeCamp (Dubey, 2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Espen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Espen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('wordnet')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(sentence, stopwords):\n",
    "    words = re.sub(\"[^\\w]\", \" \",  sentence).split()\n",
    "    numbers = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "    cleaned_text = [w.lower() for w in words if w not in stopwords and w[0] not in numbers] \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentences, stopwords):\n",
    "    words = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        extracted_words = extract_words(sentence, stopwords)\n",
    "        words.extend(extracted_words)\n",
    "        \n",
    "    words = sorted(list(set(words)))\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(word_list):\n",
    "    ss = SnowballStemmer(\"english\")\n",
    "    stemmed = []\n",
    "    for w in word_list:\n",
    "        w_stemmed = ss.stem(w)\n",
    "        if w_stemmed not in stemmed:\n",
    "            stemmed.append(w_stemmed)\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(word_list):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = []\n",
    "    for w in word_list:\n",
    "        w_lemmatized = lemmatizer.lemmatize(w)\n",
    "        if w_lemmatized not in lemmatized:\n",
    "            lemmatized.append(w_lemmatized)\n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bag(sentences, stopwords):\n",
    "    tokenized = tokenize(sentences, stopwords)\n",
    "    stemmed = stem(tokenized)\n",
    "    lemmatized = lemmatize(stemmed)\n",
    "    \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = generate_bag(data[\"text\"], stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10578"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "Creating the Naive Bayes Classifier based on the equations and pseudocode included in chapter 6 of *Speech and Language Processing* (Jurafsky & Martin, 2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"positive\", \"neutral\", \"negative\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Probability\n",
    "Number of tweets labeled a particular class divided by total number of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_prior(tweets, sentiments, classes):\n",
    "    prior = dict()\n",
    "    doc_count = tweets.count()\n",
    "    \n",
    "    for c in classes:\n",
    "        class_count = 0\n",
    "        for sentiment in y_train:\n",
    "            if sentiment == c:\n",
    "                class_count += 1\n",
    "        class_prior = class_count / doc_count\n",
    "        log_prior = math.log(class_prior)\n",
    "        prior[c] = log_prior\n",
    "    \n",
    "    return prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood\n",
    "Calculates loglikelihood[w, c] with laplace smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_likelihood(word_count, word_sums, vocab, classes):\n",
    "    likelihood = dict()\n",
    "    \n",
    "    for c in classes:\n",
    "        likelihood[c] = {}\n",
    "        for word in vocab:\n",
    "            word_likelihood = (word_count[c][word] + 1) / (word_sums[c] + 1)\n",
    "            likelihood[c][word] = math.log(word_likelihood)\n",
    "    \n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Likelihood\n",
    "Calculating likelihood relies on the following functions:\n",
    "    <ul>\n",
    "        <li>create_big_doc - Creates one long string for each class containing all tweets belonging to respective class</li>\n",
    "        <li>count_words - counts the amount of times a word appears in a class</li>\n",
    "        <li>sum_class_word_count - counts the number of words in a class's bigdoc</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_big_doc(tweets, sentiments, classes):\n",
    "    big_doc = dict()\n",
    "    for c in classes:\n",
    "        big_doc[c] = \"\"\n",
    "\n",
    "    for tweet, sentiment in zip(tweets, sentiments):\n",
    "        big_doc[sentiment] += tweet\n",
    "\n",
    "    return big_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(big_doc, vocab, classes):\n",
    "    word_count = dict()\n",
    "    for i in classes:\n",
    "        word_count[i] = {}\n",
    "\n",
    "    for c in big_doc:\n",
    "        for word in vocab:\n",
    "            word_count[c][word] = big_doc[c].count(word)\n",
    "            \n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_class_word_count(vocab, big_doc, classes):\n",
    "    word_sums = dict()\n",
    "    for c in classes:\n",
    "        x = 0\n",
    "        \n",
    "        for word in vocab:\n",
    "            x = x + big_doc[c].count(word)\n",
    "        \n",
    "        word_sums[c] = x\n",
    "    \n",
    "    \n",
    "    return word_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Naive Bayes\n",
    "Function that returns:\n",
    "    <ul>\n",
    "        <li>prior - Dictionary of every class's prior probability</li>\n",
    "        <li>likelihood - Dictionary of every word's likelihood given a class</li>\n",
    "        <li>vocab - List of the training set's vocabulary</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(x_train, y_train, classes):\n",
    "    vocab = generate_bag(x_train, stopwords)\n",
    "    \n",
    "    # Calculates P(c)\n",
    "    prior = calculate_prior(x_train, y_train, classes)\n",
    "    \n",
    "    # All tweets separated by class\n",
    "    big_doc = create_big_doc(x_train, y_train, classes)\n",
    "    \n",
    "    # Amount of times a word appears in a class\n",
    "    word_count = count_words(big_doc, vocab, classes)\n",
    "    \n",
    "    # Sum of count(w, c)\n",
    "    word_sums = sum_class_word_count(vocab, big_doc, classes)\n",
    "    \n",
    "    #P(w | c)\n",
    "    likelihood = calculate_likelihood(word_count, word_sums, vocab, classes)\n",
    "        \n",
    "    return prior, likelihood, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior, likelihood, vocab = train_naive_bayes(x_train, y_train, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Classifier\n",
    "Evaluates the the classifier using the function test_naive_bayes, which returns a test score from 0 to 1. Additionally prints all tweets in the test set with a \"correct/incorrect\"-label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(x_test, y_test, classes, prior, likelihood): \n",
    "    \n",
    "    counter = 0\n",
    "    correct_count = 0\n",
    "    classified = []\n",
    "    for sentence in x_test:\n",
    "        \n",
    "        probability = dict()\n",
    "        \n",
    "        for c in classes:\n",
    "            probability[c] = prior[c]\n",
    "            for word in lemmatize(stem(extract_words(sentence, stopwords))):\n",
    "                if word in likelihood[c].keys():\n",
    "                    probability[c] = probability[c] + likelihood[c][word]\n",
    "        max_prob = -1000000\n",
    "        for class_probability in probability:\n",
    "            if probability[class_probability] > max_prob:\n",
    "                max_prob = probability[class_probability]\n",
    "                max_prob_class = class_probability\n",
    "        \n",
    "        classified.append((max_prob_class, sentence))\n",
    "    \n",
    "    for estimated_class, actual_class in zip(classified, y_test):\n",
    "\n",
    "        if estimated_class[0] == actual_class:\n",
    "            guess = \"CORRECT\"\n",
    "            correct_count += 1\n",
    "        #else:\n",
    "         #   guess =\"INCORRECT\"\n",
    "\n",
    "        #print(\" #####\", guess, \"##### \\n # Tweet:\", estimated_class[1], \"\\n # Prediction:\", estimated_class[0], \"\\n # Actual:\", actual_class, \"\\n\")\n",
    "        counter += 1\n",
    "    \n",
    "    test_score = correct_count / counter\n",
    "    return test_score, classified\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for printing out tweets witht their predicted class and actual class.\n",
    "\n",
    "def print_correct_incorrect(classified_tweets, tweets_sentiment, print_start, print_num):\n",
    "    \n",
    "    for estimated_class, actual_class in zip(classified_tweets[print_start:print_num], tweets_sentiment[print_start:print_num]):\n",
    "\n",
    "        if estimated_class[0] == actual_class:\n",
    "            guess = \"CORRECT\"\n",
    "\n",
    "        else:\n",
    "             guess =\"INCORRECT\"\n",
    "\n",
    "        print(\" #####\", guess, \"##### \\n # Tweet:\", estimated_class[1], \"\\n # Prediction:\", estimated_class[0], \"\\n # Actual:\", actual_class, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score, classified = test_naive_bayes(x_test, y_test, classes, prior, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ##### CORRECT ##### \n",
      " # Tweet: @JetBlue No, he didn't have more info. I was more infuriated by the way previous rep treated me. how she can possibly work as a JetBlue rep? \n",
      " # Prediction: negative \n",
      " # Actual: negative \n",
      "\n",
      " ##### CORRECT ##### \n",
      " # Tweet: @united is a money sucking airline with terrible terrible customer service \n",
      " # Prediction: negative \n",
      " # Actual: negative \n",
      "\n",
      " ##### INCORRECT ##### \n",
      " # Tweet: @AmericanAir and btwn gate a8 &amp; a15 I lost a diamond earring #dayjustgotWORSE! Pls have maintenance look for it!! http://t.co/UieSR3GHHO \n",
      " # Prediction: positive \n",
      " # Actual: neutral \n",
      "\n",
      " ##### CORRECT ##### \n",
      " # Tweet: @USAirways #ShoutOut 2 Kristie(sp?) from Gate4 @ PVD today. She's a #RockStar, was a tremendous help in a tough situation. #PromoteThatGirl \n",
      " # Prediction: positive \n",
      " # Actual: positive \n",
      "\n",
      " ##### CORRECT ##### \n",
      " # Tweet: @USAirways My family, friends and colleagues will NEVER  fly USAir again. Bad weather happens. The good airlines seem to communicate better. \n",
      " # Prediction: negative \n",
      " # Actual: negative \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_correct_incorrect(classified, y_test, 21, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score using test score from test_naive_bayes\n",
    "print(\"Test score: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.67\n"
     ]
    }
   ],
   "source": [
    "# Accuracy score using sklearns accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Test score: {:.2f}\".format(accuracy_score(y_test, [x[0] for x in classified])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Command Line Utility\n",
    "Takes a tweet as user input and computes the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_tweet(prior, likelihood, classes):\n",
    "    user_tweet = str(input(\">Type in your tweet: \"))\n",
    "    probability = dict()\n",
    "    \n",
    "    for c in classes:\n",
    "        probability[c] = prior[c]\n",
    "        for word in lemmatize(stem(extract_words(user_tweet, stopwords))):\n",
    "            if word in likelihood[c].keys():\n",
    "                    probability[c] = probability[c] + likelihood[c][word]\n",
    "        \n",
    "\n",
    "    max_prob = -1000000\n",
    "    for class_probability in probability:\n",
    "        if probability[class_probability] > max_prob:\n",
    "            max_prob = probability[class_probability]\n",
    "            max_prob_class = class_probability\n",
    "        \n",
    "    classified = (max_prob_class, user_tweet)\n",
    "    print(\"Class:\", classified[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Type in your tweet: @JetBlue No, he didn't have more info. I was more infuriated by the way previous rep treated me. how she can possibly work as a JetBlue rep?\n",
      "Class: negative\n"
     ]
    }
   ],
   "source": [
    "prompt_tweet(prior, likelihood, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation Generator\n",
    "A function that takes a tweet and its classification as user input and returns the words that have contributed in classifying the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanation(classes, likelihood):\n",
    "    tweet = input(\">Type in your tweet: \")\n",
    "    predicted_class = input(\">Type in predicted class {}: \".format(classes))\n",
    "    while predicted_class not in classes:\n",
    "        predicted_class = input(\"Please enter a valid class {}\".format(classes))\n",
    "    split_words = extract_words(tweet, stopwords)\n",
    "    class_words = []\n",
    "    word_weights = dict()\n",
    "    original_words = dict()\n",
    "    for c in classes:\n",
    "        word_weights[c] = {}\n",
    "    \n",
    "    i = 0\n",
    "    for word in lemmatize(stem(split_words)):\n",
    "        \n",
    "        original_words[word] = split_words[i]\n",
    "        i += 1\n",
    "        for c in classes:\n",
    "            if word in likelihood[c].keys():\n",
    "                word_weights[c][word] = likelihood[c][word]\n",
    "                \n",
    "    for word in word_weights[predicted_class].keys():\n",
    "        max_score = word_weights[predicted_class][word]\n",
    "        \n",
    "        for c in classes: \n",
    "            if word_weights[c][word] > max_score:\n",
    "                max_score = word_weights[c][word]\n",
    "        \n",
    "        if max_score == word_weights[predicted_class][word]: \n",
    "            class_words.append((word, max_score))\n",
    "    \n",
    "    n = len(class_words)\n",
    "                \n",
    "    print(\"\\n TWEET: \\n '\" + tweet + \"' \\n \\n has been classified as\", predicted_class.upper(), \"\\n \\\n",
    "because the following\", n, \"words are likely to appear in a\", predicted_class, \"tweet:\")\n",
    "    for item in class_words:\n",
    "        print(\"        - \" + original_words[item[0]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Type in your tweet: @united not 100% sure, however my ticket included one checked bag, therefore this charge was extra and completely unanticipated.\n",
      ">Type in predicted class ['positive', 'neutral', 'negative']: negative\n",
      "\n",
      " TWEET: \n",
      " '@united not 100% sure, however my ticket included one checked bag, therefore this charge was extra and completely unanticipated.' \n",
      " \n",
      " has been classified as NEGATIVE \n",
      " because the following 5 words are likely to appear in a negative tweet:\n",
      "        - one\n",
      "        - bag\n",
      "        - charge\n",
      "        - extra\n",
      "        - completely\n"
     ]
    }
   ],
   "source": [
    "generate_explanation(classes, likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "## Correctly predicted\n",
    "The tweet \"@SouthwestAir Already signed up!  Thanks!  Looking forward to trying the Southwest experience.\" was correctly predicted as positive, because of words such as \"already\", \"thanks\", \"looking\", \"forward\", and \"experience\".\n",
    "\n",
    "\"@AmericanAir @yvonneokaka When do I get my personal response and apology for your crew's having forgotten to load baggage onto my flight?\" was correctly predicted as negative, since it included words such as \"personal\", \"apology\", \"load\", and \"baggage\" which commonly appear in negative tweets.\n",
    "\n",
    "## Incorrectly predicted\n",
    "\n",
    "The tweet \"@USAirways Will do :)\" is wrongly classified as negative when it actually should be classified as positive instead. This error can be a result of several factors, one being that it is too short to properly benefit from the likelihood of words, making the prediction too much based upon the prior probability, which is biased towards the class \"negative\" because the amount of negative tweets in the training set is significantly larger than the other classes. In addition, the smiley face is ignored, which for humans is usually a sign of positivity.\n",
    "\n",
    "\"@AmericanAir thanks.  I actually made it, my connection flight was delayed.  Guess all delays are not a bad thing.\" was classified as negative, when in fact its sentiment is positive. This error occured because of the presence of words such as \"delayed\", \"delays\", and \"bad\", which are words that usually indicate that the tweet likely is negative.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "Dubey, P. (2018, 18. December). An introduction to Bag of Words and how to code it in Python for NLP. *freeCodeCamp*. Retrieved from https://www.freecodecamp.org/\n",
    "\n",
    "Jurafsky, D., & Martin, J. H. (2017). Speech and language processing. Upper Saddle River, NJ: Prentice Hall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
